version: "3.9"
services:
  app:
    build:
      context: .
    image: kmouts_pytorch:latest
    container_name: mypytorch
#    command: nvidia-smi
#    command: python -c "import torch; print('__CUDA Device Name:',torch.cuda.get_device_name(0))"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu, compute, graphics, utility, video, display]

    ports:
      - "8888:8888"
    volumes:
      - .:/opt/project
      - /mnt/DATA/DATASETS:/DATASETS
      - /tmp/.X11-unix:/tmp/.X11-unix
      - /home/kmouts/.Xauthority:/tmp/.docker.xauth
    environment:
      - DISPLAY=:0
      - NVIDIA_VISIBLE_DEVICES=all
      - XAUTH=/tmp/.docker.xauth
      - XSOCK=/tmp/.X11-unix


#    command: /usr/bin/nvidia-smi
#    command:
#      - /bin/bash

